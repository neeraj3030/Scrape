{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site='http://dl9.heyserver.in/film/'\n",
    "sauce=urllib.request.urlopen(site).read()\n",
    "soup=bs.BeautifulSoup(sauce,'lxml')\n",
    "pickle_out=open('movies.pickle','wb')\n",
    "pickle.dump(soup,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "'''to get all links in body of page'''\n",
    "\n",
    "df=pd.DataFrame()\n",
    "pickle_in=open('movies.pickle','rb')\n",
    "soup_pickle=pickle.load(pickle_in)\n",
    "\n",
    "mov_list=[]          ##this was at __ & fucked my 3 hours \n",
    "\n",
    "for url in soup_pickle.find_all('a'):\n",
    "    #print(url.get('href'))\n",
    "    date=url.get('href')\n",
    "    \n",
    "    if date=='../':\n",
    "        continue\n",
    "    \n",
    "    full=site+date\n",
    "    #print(full)       # __\n",
    "    \n",
    "    sauce=urllib.request.urlopen(full).read()\n",
    "    soup=bs.BeautifulSoup(sauce,'lxml')\n",
    "    \n",
    "    \n",
    "    for url in soup.find_all('a'):\n",
    "        #print(url.get('href'))\n",
    "        mov_name=url.get('href')\n",
    "        \n",
    "        \n",
    "        if mov_name=='../':\n",
    "            continue\n",
    "        \n",
    "        mov_link=full+mov_name\n",
    "        mov_list.append((mov_name,mov_link))   # tuple has less overhead than list\n",
    "        #print(mov_name)\n",
    "        \n",
    "    \n",
    "         \n",
    "        \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(mov_list,columns={'movies','links'})\n",
    "df.to_csv('links.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('links.csv')\n",
    "df[['links']].head()\n",
    "df[df['movies']== '22.July.2018.1080p.WEB-DL.6CH.x264.mkv']\n",
    "#print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie=input('ENTER THE MOVIE NAME\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=[]\n",
    "for char in list(movie):\n",
    "    if ord(char)!=32:\n",
    "        res.append(char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r', 'e', 'd', 's', 'p', 'a', 'r', 'r', 'o', 'w']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
